{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should definetely watch this movie!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python310\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:34:46.074642Z",
     "iopub.status.busy": "2024-11-06T18:34:46.074262Z",
     "iopub.status.idle": "2024-11-06T18:35:38.680346Z",
     "shell.execute_reply": "2024-11-06T18:35:38.679296Z",
     "shell.execute_reply.started": "2024-11-06T18:34:46.074600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -q sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:38.683119Z",
     "iopub.status.busy": "2024-11-06T18:35:38.682736Z",
     "iopub.status.idle": "2024-11-06T18:35:52.009437Z",
     "shell.execute_reply": "2024-11-06T18:35:52.008467Z",
     "shell.execute_reply.started": "2024-11-06T18:35:38.683082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import nltk\n",
    "import faiss #For calculating similarity between embeddings. \n",
    "from sentence_transformers import SentenceTransformer #For Sentence Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:52.011130Z",
     "iopub.status.busy": "2024-11-06T18:35:52.010593Z",
     "iopub.status.idle": "2024-11-06T18:35:53.776194Z",
     "shell.execute_reply": "2024-11-06T18:35:53.775219Z",
     "shell.execute_reply.started": "2024-11-06T18:35:52.011102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plots = pd.read_csv('wiki_movie_plots_deduped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.779462Z",
     "iopub.status.busy": "2024-11-06T18:35:53.779073Z",
     "iopub.status.idle": "2024-11-06T18:35:53.829423Z",
     "shell.execute_reply": "2024-11-06T18:35:53.828521Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.779427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 5337 to 8135\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Release Year      2000 non-null   int64 \n",
      " 1   Title             2000 non-null   object\n",
      " 2   Origin/Ethnicity  2000 non-null   object\n",
      " 3   Director          2000 non-null   object\n",
      " 4   Cast              1917 non-null   object\n",
      " 5   Genre             2000 non-null   object\n",
      " 6   Wiki Page         2000 non-null   object\n",
      " 7   Plot              2000 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 140.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# plots.info() \n",
    "subset_500 = plots.sample(n=2000, random_state=42)\n",
    "subset_500.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.831387Z",
     "iopub.status.busy": "2024-11-06T18:35:53.830682Z",
     "iopub.status.idle": "2024-11-06T18:35:53.847746Z",
     "shell.execute_reply": "2024-11-06T18:35:53.846859Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.831349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>1951</td>\n",
       "      <td>The Day the Earth Stood Still</td>\n",
       "      <td>American</td>\n",
       "      <td>Robert Wise</td>\n",
       "      <td>Michael Rennie, Patricia Neal</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Day_the_Eart...</td>\n",
       "      <td>When a flying saucer lands in Washington, D.C....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9809</th>\n",
       "      <td>1981</td>\n",
       "      <td>The Burning</td>\n",
       "      <td>American</td>\n",
       "      <td>Tony Maylam</td>\n",
       "      <td>Brian Matthews, Holly Hunter, Jason Alexander</td>\n",
       "      <td>horror</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Burning_(film)</td>\n",
       "      <td>One night at Camp Blackfoot, several campers p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24075</th>\n",
       "      <td>2012</td>\n",
       "      <td>Nobel Chor</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Suman Ghosh</td>\n",
       "      <td>Mithun Chakraborty, Saswata Chatterjee, Sudipt...</td>\n",
       "      <td>suspense / drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Nobel_Chor</td>\n",
       "      <td>The first Asian Nobel Laureate, Rabindranath T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19057</th>\n",
       "      <td>1952</td>\n",
       "      <td>Trent's Last Case</td>\n",
       "      <td>British</td>\n",
       "      <td>Herbert Wilcox</td>\n",
       "      <td>Michael Wilding, Margaret Lockwood, Orson Welles</td>\n",
       "      <td>detective</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Trent%27s_Last_C...</td>\n",
       "      <td>A major international financier is found dead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>1977</td>\n",
       "      <td>Aafat</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>Atma Ram</td>\n",
       "      <td>Navin Nischol, Leena Chandavarkar, Amjad Khan,...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aafat</td>\n",
       "      <td>Inspector Amar and Inspector Chhaya are after ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                          Title Origin/Ethnicity   \n",
       "5337           1951  The Day the Earth Stood Still         American  \\\n",
       "9809           1981                    The Burning         American   \n",
       "24075          2012                     Nobel Chor          Bengali   \n",
       "19057          1952              Trent's Last Case          British   \n",
       "24991          1977                          Aafat        Bollywood   \n",
       "\n",
       "             Director                                               Cast   \n",
       "5337      Robert Wise                      Michael Rennie, Patricia Neal  \\\n",
       "9809      Tony Maylam      Brian Matthews, Holly Hunter, Jason Alexander   \n",
       "24075     Suman Ghosh  Mithun Chakraborty, Saswata Chatterjee, Sudipt...   \n",
       "19057  Herbert Wilcox   Michael Wilding, Margaret Lockwood, Orson Welles   \n",
       "24991        Atma Ram  Navin Nischol, Leena Chandavarkar, Amjad Khan,...   \n",
       "\n",
       "                  Genre                                          Wiki Page   \n",
       "5337    science fiction  https://en.wikipedia.org/wiki/The_Day_the_Eart...  \\\n",
       "9809             horror   https://en.wikipedia.org/wiki/The_Burning_(film)   \n",
       "24075  suspense / drama           https://en.wikipedia.org/wiki/Nobel_Chor   \n",
       "19057         detective  https://en.wikipedia.org/wiki/Trent%27s_Last_C...   \n",
       "24991           unknown                https://en.wikipedia.org/wiki/Aafat   \n",
       "\n",
       "                                                    Plot  \n",
       "5337   When a flying saucer lands in Washington, D.C....  \n",
       "9809   One night at Camp Blackfoot, several campers p...  \n",
       "24075  The first Asian Nobel Laureate, Rabindranath T...  \n",
       "19057  A major international financier is found dead ...  \n",
       "24991  Inspector Amar and Inspector Chhaya are after ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_500.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.849736Z",
     "iopub.status.busy": "2024-11-06T18:35:53.848987Z",
     "iopub.status.idle": "2024-11-06T18:35:53.858227Z",
     "shell.execute_reply": "2024-11-06T18:35:53.857366Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.849699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23976                               romance\n",
       "17202    action, adventure, fantasy, sci-fi\n",
       "23187                               unknown\n",
       "517                                   drama\n",
       "4877                                  drama\n",
       "Name: Genre, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_500['Genre'].sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.859507Z",
     "iopub.status.busy": "2024-11-06T18:35:53.859190Z",
     "iopub.status.idle": "2024-11-06T18:35:53.871628Z",
     "shell.execute_reply": "2024-11-06T18:35:53.870733Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.859480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_500['Genre'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.873450Z",
     "iopub.status.busy": "2024-11-06T18:35:53.872827Z",
     "iopub.status.idle": "2024-11-06T18:35:53.878717Z",
     "shell.execute_reply": "2024-11-06T18:35:53.877814Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.873418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_len(row: str):\n",
    "    length_all = 0 \n",
    "    number_of_samples = len(subset_500)\n",
    "    for delta in plots[row]:\n",
    "        length_all += len(delta) #We add length of the each plot to 'length_all'.\n",
    "    \n",
    "    return round((length_all / number_of_samples))\n",
    "\n",
    "#This function above will help us to demonstrate average length of the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.879976Z",
     "iopub.status.busy": "2024-11-06T18:35:53.879720Z",
     "iopub.status.idle": "2024-11-06T18:35:53.900167Z",
     "shell.execute_reply": "2024-11-06T18:35:53.899361Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.879954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37765\n"
     ]
    }
   ],
   "source": [
    "lengths = get_len('Plot') #Average length of the plots.\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:35:53.904415Z",
     "iopub.status.busy": "2024-11-06T18:35:53.904128Z",
     "iopub.status.idle": "2024-11-06T18:36:00.552084Z",
     "shell.execute_reply": "2024-11-06T18:36:00.551091Z",
     "shell.execute_reply.started": "2024-11-06T18:35:53.904392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sen_transformer = SentenceTransformer('all-mpnet-base-v2') #Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:36:00.553553Z",
     "iopub.status.busy": "2024-11-06T18:36:00.553257Z",
     "iopub.status.idle": "2024-11-06T18:36:00.660826Z",
     "shell.execute_reply": "2024-11-06T18:36:00.660086Z",
     "shell.execute_reply.started": "2024-11-06T18:36:00.553526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yake #Library for keyword extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function below takes movie plots as an input and returns a list which contains all keywords for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:36:00.662373Z",
     "iopub.status.busy": "2024-11-06T18:36:00.661974Z",
     "iopub.status.idle": "2024-11-06T18:36:00.681421Z",
     "shell.execute_reply": "2024-11-06T18:36:00.680531Z",
     "shell.execute_reply.started": "2024-11-06T18:36:00.662335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_keywords():\n",
    "    kw_extraction = yake.KeywordExtractor(lan = 'en', n = 3, top = 25)\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    sentences = []\n",
    "    total_iteration = len(plots.sample(25000))\n",
    "    with tqdm(total= total_iteration) as pbar:\n",
    "        for delta in plots['Plot']:\n",
    "            texts = []\n",
    "            keywords = kw_extraction.extract_keywords(delta)\n",
    "            for keyword, _ in keywords:\n",
    "                texts.append(keyword.lower())\n",
    "\n",
    "            joined_text = ','.join(texts)\n",
    "            sentences.append(joined_text)\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:36:00.682911Z",
     "iopub.status.busy": "2024-11-06T18:36:00.682586Z",
     "iopub.status.idle": "2024-11-06T18:36:00.687816Z",
     "shell.execute_reply": "2024-11-06T18:36:00.686960Z",
     "shell.execute_reply.started": "2024-11-06T18:36:00.682886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm  # Import the progress bar library\n",
    "import numpy as np  # Ensure this is imported if not already\n",
    "\n",
    "\n",
    "def get_embeddings(dataframe):\n",
    "    num_of_sentence = []\n",
    "    sentences = []\n",
    "    embeddings_for_each_plot = []\n",
    "    final_embeddings = []\n",
    "    prev_delta = 0\n",
    "    pooling = 'sum'\n",
    "\n",
    "    # Initialize progress bar for processing plots\n",
    "    for delta in tqdm(dataframe['Plot'], desc=\"Processing plots\"):\n",
    "        text = sent_tokenize(delta)\n",
    "        num_of_sentence.append(len(text))\n",
    "        sentences.extend(text)\n",
    "\n",
    "    # Compute embeddings for all sentences\n",
    "    print(\"We are here\")\n",
    "    embeddings = sen_transformer.encode(sentences)\n",
    "    print(\"Here\")\n",
    "    # Initialize progress bar for embedding aggregation\n",
    "    for sentence_count in tqdm(num_of_sentence, desc=\"Aggregating embeddings\"):\n",
    "        plot_embeddings = embeddings[prev_delta:prev_delta + sentence_count]\n",
    "        embeddings_for_each_plot.append(plot_embeddings)\n",
    "        prev_delta += sentence_count\n",
    "\n",
    "    # Aggregate embeddings for each plot\n",
    "    for sentence_embeddings in tqdm(embeddings_for_each_plot, desc=\"Finalizing embeddings\"):\n",
    "        if pooling == 'sum':\n",
    "            aggregated = np.sum(sentence_embeddings, axis=0)\n",
    "        elif pooling == 'mean':\n",
    "            aggregated = np.mean(sentence_embeddings, axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pooling method. Choose 'sum' or 'mean'.\")\n",
    "        final_embeddings.append(aggregated)\n",
    "\n",
    "    return final_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T18:36:00.689090Z",
     "iopub.status.busy": "2024-11-06T18:36:00.688822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# keywordsALL = get_keywords() #Get all the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = get_embbedings(subset_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing plots: 100%|██████████| 2000/2000 [00:00<00:00, 2862.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are here\n",
      "Here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating embeddings: 100%|██████████| 2000/2000 [00:00<00:00, 666927.02it/s]\n",
      "Finalizing embeddings: 100%|██████████| 2000/2000 [00:00<00:00, 68098.19it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_embeddings(subset_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to pickle\n",
    "with open('embeddings.pkl', 'wb') as file:\n",
    "    pickle.dump(embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# embeddings = sen_transformer.encode(keywordsALL) #Get the embeddings from keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#This function takes plot_index, embeddings, number of similar plots that you want to see and \n",
    "# returns the index of similar movies in the dataset.\n",
    "\n",
    "def get_similarity(plot_index, embeddings, num_of_similars):\n",
    "    embeddings = np.array(embeddings, dtype='float32')\n",
    "\n",
    "    # It uses L2 norm for calculating similarity\n",
    "    similarity = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    similarity.add(embeddings)\n",
    "\n",
    "    query_vector = embeddings[plot_index].reshape(1, -1)  \n",
    "    \n",
    "    D, I = similarity.search(query_vector, num_of_similars) \n",
    "\n",
    "    return I,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes user input and gives moves similar to user discription.\n",
    "\"\"\"\n",
    "\n",
    "def get_similarity_from_plot(user_input, embeddings, num_of_similars, print_plot):\n",
    "    \n",
    "    embeddings = np.array(embeddings, dtype='float32')\n",
    "\n",
    "    similarity = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    similarity.add(embeddings)\n",
    "    \n",
    "    input_embedding = sen_transformer.encode(user_input)\n",
    "    query_vector = input_embedding.reshape(1, -1)\n",
    "\n",
    "    D, I = similarity.search(query_vector, num_of_similars)\n",
    "    \n",
    "    # Reset the index of the movies DataFrame\n",
    "    movies_reset_index = subset_500.reset_index(drop=True)\n",
    "\n",
    "    movie_titles = movies_reset_index.loc[I.reshape(-1), 'Title'].tolist()\n",
    "    movie_plots = movies_reset_index.loc[I.reshape(-1), 'Plot'].tolist()\n",
    "    \n",
    "    print(f'I recommend, {movie_titles}')\n",
    "    \n",
    "    if print_plot:\n",
    "        rand_index = np.random.randint(num_of_similars)\n",
    "        print(f'Here is the plot for {movie_titles[rand_index]}:\\n{movie_plots[rand_index]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  43 245  20 179]\n"
     ]
    }
   ],
   "source": [
    "indexes,Dick = get_similarity(\n",
    "    plot_index=1, embeddings=embeddings, num_of_similars=5)\n",
    "print(indexes.reshape(-1))\n",
    "print(Dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Luke Skywalker stays with his aunt and uncle on a farm on Tatooine. \n",
    "He is desperate to get off this planet and get to the Academy like his friends, \n",
    "but his uncle needs him for the next harvest. Meanwhile, an evil emperor has taken over the galaxy, \n",
    "and has constructed a formidable \"Death Star\" capable of destroying whole planets. \n",
    "Princess Leia, a leader in the resistance movement, acquires plans of the Death Star, \n",
    "places them in R2-D2, a droid, and sends him off to find Obi-wan Kenobi. Before he finds him, \n",
    "R2-D2 ends up on the Skywalkers' farm with his friend C-3PO. R2-D2 then wanders into the desert, \n",
    "and when Luke follows, they eventually come across Obi-wan. Will Luke, Obi-wan, and the two droids \n",
    "be able to destroy the Death Star, or will the Emperor rule forever?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to try our 'dummy model'. I copied the plot for Star Wars: Episode IV - A New Hope, let's see if the model can recommend us the similar movies based on its plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend, ['Deaf Sam-yong', 'Wu Kong', 'Jakkanna', \"Rustlers' Hideout\"]\n"
     ]
    }
   ],
   "source": [
    "get_similarity_from_plot(user_input = text, embeddings = embeddings, num_of_similars = 4, print_plot = False)\n",
    "\n",
    "#If print_plot set True you can print the plots for movies that our model recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, It knows the plot is about 'wars' in the stars and hey look, it recommend another movie except Star Wars franchise! Let's try again with different plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text2 = \"\"\" In sun-kissed Los Angeles, a pair of morning commuters jammed on a wide stretch of highway are off to a rocky start. But suave Sebastian, a charming jazz pianist whom life's got him on the ropes, and lovely Mia, a brilliant playwright waiting for her big break, are meant for each other. On the one hand, Sebastian thinks he has a serious plan for the future. On the other hand, Mia squanders herself in meaningless auditions, mesmerised by old Hollywood glamour. However, as the incurable romantics keep running into each other under the city's starry nights and plum-hued sunrises, a magical, old-school tap-dance romance timidly begins. Such is the power of effervescent love: it inspires people to have long walks while gazing at the colourful Milky Way of the city's flickering lights. But life is as exciting as it is challenging. After all, no one knows what tomorrow holds. And as the young idealists veer from their dreams, questions arise. Does true love exist only in movies? Do dreams come true in real life?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend, ['Open Tee Bioscope', 'Seven Footprints to Satan', 'In Search of Gregory']\n"
     ]
    }
   ],
   "source": [
    "get_similarity_from_plot(user_input = text2, embeddings = embeddings, num_of_similars = 3, print_plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend, ['Seven Footprints to Satan', 'The Nun and the Bandit', 'Wu Kong']\n"
     ]
    }
   ],
   "source": [
    "text3 = \"\"\"\n",
    "Jim and his fiancee Eve, a young society couple, are kidnapped on the eve of Jim's departure for Africa and brought to a mansion that is home to a strange and glamorous cult with a hooded leader called \"Satan.\" Jim is put through a number of strange adventures in the old house and tries to maintain his courage. During the course of the film, Jim encounters an old witch, a dwarf, a gorilla and a strange shaggy creature called \"The Spider\". In the end, he is confronted by Satan himself who puts him to a final test.\n",
    "\n",
    "It is revealed to be a hoax played on Jim by his uncle Joe, Eve, and his uncle's employees to convince Jim to forget his adventure plans, stay at home, work for his uncle, and settle down with Eve.\n",
    "\"\"\"\n",
    "get_similarity_from_plot(\n",
    "    user_input=text3, embeddings=embeddings, num_of_similars=3, print_plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 64890,
     "sourceId": 127736,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
